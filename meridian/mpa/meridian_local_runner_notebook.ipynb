{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44797b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "home_dir = \"/Users/mariappan.subramanian/Documents/\"\n",
    "sys.path.append(f'{home_dir}/repo/forked/meridian/meridian/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9014b5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 25.8 gigabytes of available RAM\n",
      "\n",
      "Num GPUs Available:  0\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import arviz as az\n",
    "import IPython\n",
    "import altair as alt\n",
    "from IPython.display import HTML\n",
    "import gc\n",
    "\n",
    "from meridian.mpa.mpa_utils_meridian import MeridianMPAInput\n",
    "\n",
    "from meridian import constants\n",
    "from meridian.data import load\n",
    "from meridian.data import test_utils\n",
    "from meridian.model import model\n",
    "from meridian.model import spec\n",
    "from meridian.model import prior_distribution\n",
    "from meridian.analysis import optimizer\n",
    "from meridian.analysis import analyzer\n",
    "from meridian.analysis import visualizer\n",
    "from meridian.analysis import summarizer\n",
    "from meridian.analysis import formatter\n",
    "\n",
    "# check if GPU is available\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199ccea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from client_config import client_config, ec50_multiplier_config, media_parameters_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10cf9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_to_columns = load.CoordToColumns(\n",
    "    time='time',\n",
    "    geo='geo',\n",
    "    controls=['sentiment_score_control', 'competitor_activity_score_control'],\n",
    "    population='population',\n",
    "    kpi='conversions',\n",
    "    revenue_per_kpi='revenue_per_conversion',\n",
    "    media=[\n",
    "        'Channel0_impression',\n",
    "        'Channel1_impression',\n",
    "        'Channel2_impression',\n",
    "    ],\n",
    "    media_spend=[\n",
    "        'Channel0_spend',\n",
    "        'Channel1_spend',\n",
    "        'Channel2_spend',\n",
    "    ],\n",
    "    reach =['Channel3_reach'],\n",
    "    frequency=['Channel3_frequency'],\n",
    "    rf_spend=['Channel3_spend'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9376c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_media_to_channel = {\n",
    "    'Channel0_impression': 'Channel_0',\n",
    "    'Channel1_impression': 'Channel_1',\n",
    "    'Channel2_impression': 'Channel_2',\n",
    "}\n",
    "correct_media_spend_to_channel = {\n",
    "    'Channel0_spend': 'Channel_0',\n",
    "    'Channel1_spend': 'Channel_1',\n",
    "    'Channel2_spend': 'Channel_2',\n",
    "}\n",
    "\n",
    "correct_reach_to_channel = {\n",
    "    'Channel3_reach': 'Channel3',\n",
    "}\n",
    "correct_frequency_to_channel = {\n",
    "    'Channel3_frequency': 'Channel3',\n",
    "}\n",
    "correct_rf_spend_to_channel = {\n",
    "    'Channel3_spend': 'Channel3',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f26b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = load.CsvDataLoader(\n",
    "    csv_path=\"https://raw.githubusercontent.com/google/meridian/refs/heads/main/meridian/data/simulated_data/csv/geo_media_rf.csv\",\n",
    "    kpi_type='non_revenue',\n",
    "    coord_to_columns=coord_to_columns,\n",
    "    media_to_channel=correct_media_to_channel,\n",
    "    media_spend_to_channel=correct_media_spend_to_channel,\n",
    "    reach_to_channel=correct_reach_to_channel,\n",
    "    frequency_to_channel=correct_frequency_to_channel,\n",
    "    rf_spend_to_channel=correct_rf_spend_to_channel,\n",
    ")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517bcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1754767860.199575 4776487 service.cc:148] XLA service 0x131211a10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1754767860.199647 4776487 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1754767860.294065 4776487 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "roi_rf_mu = 0.2     # Mu for ROI prior for each RF channel.\n",
    "roi_rf_sigma = 0.9  # Sigma for ROI prior for each RF channel.\n",
    "prior = prior_distribution.PriorDistribution(\n",
    "    roi_rf=tfp.distributions.LogNormal(roi_rf_mu, roi_rf_sigma, name=constants.ROI_RF)\n",
    ")\n",
    "model_spec = spec.ModelSpec(prior=prior)\n",
    "\n",
    "mmm = model.Meridian(input_data=data, model_spec=model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 14:34:45.791336: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "W0000 00:00:1754768086.910438 4776487 assert_op.cc:38] Ignoring Assert operator mcmc_retry_init/assert_equal_1/Assert/AssertGuard/Assert\n"
     ]
    }
   ],
   "source": [
    "run_model = True\n",
    "file_path = f'{home_dir}/repo/forked/meridian/meridian/mpa/demo_rf_model_obj.pkl'\n",
    "if run_model:\n",
    "  mmm.sample_prior(500)\n",
    "  mmm.sample_posterior(n_chains=2, n_adapt=1000, n_burnin=500, n_keep=1000, seed=1)\n",
    "  model.save_mmm(mmm, file_path)\n",
    "else:\n",
    "  mmm=model.load_mmm(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ff92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmm = model.load_mmm(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af39aa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<meridian.model.model.Meridian at 0x3bd184980>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76715ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
